---
layout: post
title: Artículo Clase 6----> "Fix You" ((https://music.youtube.com/search?q=fix+you+with+lyrics))
---

##Bienvenidos al primer artículo de una serie de 3

El tema de la explicabilidad y transparencia es muy relevante sobre todo para los sistemas de inteligencia artificial y recomendación que tienen interacción directa con los usuarios los que terminan afectando sus elecciones y decisiones. Tal como vimos en clases con el ejemplo de las recomendaciones de "Youtube" respecto de los videos que se están recomendando, donde vimos que existe una mayor probabilidad de que se nos recomiende videos que tienen contenidos sesgados hacia “fake news” o donde existiría mala calidad de contenidos.   
Con la evolución de los sistemas recomendadores desde aquellos que partían con agrupamiento por similaridad (Knn), a los de factorización matricial (MF) y llegando a aquellos que usan redes neuronales profundas (DNN), la interpretabilidad se ha reducido pero aumentando la predictibilidad, y donde además, las redes neuronales de punta, dada la profundidad y extensión necesarias, pueden ser entrenadas sólo por las grandes empresas tecnológicas (donde la gran mayoría basa su modelo de negocios en recomendaciones a usuarios, como Meta, Alphabet, Twitter, Amazon etc ), acentúan aún más los problemas de  transparencia dado que en la academia no se cuenta con los recursos (poder de computo y almacenamiento) necesario para ir probando y disectando estos modelos para entender cuales son los sesgos que estos  modelos avanzados aprenden. 
Por ejemplo, como es expuesto por Milano, S., Taddeo, M., & Floridi, L (2020)*, existen muy importantes consecuencias éticas que se deben discutir en estos sistemas. Algunos sistemas podrían estar intentando crear “adicción” a cierto tipo de recomendaciones (contenido, productos, comportamientos) al limitar el rango de opciones a cual los usuarios se encuentran expuestos. Así también, no existen estudios respecto de como la influencia y modificación de conducta experimentada en las plataformas digitales pueden influeciar la conducta en el mundo ”real”. Siuna plataforma tipo red social recomienda a un usuario contenido que con mayor probabilidad incita comportamientos violentos, los que a su vez aumentan la probabilidad que este usuario se comporte violentamente, se genera un “loop” que se iría retroalimentando. 
Dado lo anterior, y las consecuencias de sistemas cada vez más complejos, donde la academia tendría menor capacidad de “estudiar” y “disectar” estos modelos para lograr un mayor comprensión de sus alcances, es que una idea es intentar incentivar el uso de protocolos y standards de autoregulación, en las recomendaciones. 
Es entonces que la tarea estará en poder diseñar cuales serían estos standards, donde  creo es de suma importancia es que sean equipos multidisiplinarios de ciencias sociales, computacional y biológicas sean quienes puedan generar estos principios comunes necesarios para reducir los efectos de los sesgos, explicabilidad y transparencia de los ouput generados por los sistemas recomendadores de última generación.  Y así como sugiere la canción “Fix You” de Coldplay,  sería necesario para estos sistemas que  “...Las luces (de equipos multidisciplinarios) guien de vuelta al hogar (a los sistemas) y se encienda en los huesos (la discusión)….”

Milano, S.; Taddeo, M.; Floridi, L. Recommender systems and their ethical challenges. AI Soc. 2020
